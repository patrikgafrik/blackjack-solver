{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1c47e6",
   "metadata": {},
   "source": [
    "## 1. Genetický algoritmus\n",
    "\n",
    "Tento kód implementuje genetický algoritmus (GA) na optimalizáciu stratégií pre hru Blackjack. Cieľom je nájsť optimálnu stratégiu rozhodovania sa (**hit/stand**), ktorá maximalizuje očakávaný výnos hráča.\n",
    "\n",
    "### Parametre genetického algoritmu\n",
    "- **population_size** (predvolená hodnota: 50): Veľkosť populácie (počet stratégií v každej generácii)\n",
    "- **mutation_rate** (predvolená hodnota: 0.01): Pravdepodobnosť mutácie každého rozhodnutia v stratégii\n",
    "- **generations** (predvolená hodnota: 100): Počet generácií pre GA\n",
    "- **elite_count** (nastavené na 2): Počet najlepších jedincov, ktorí sú zachovaní bez zmien do ďalšej generácie\n",
    "\n",
    "### Inicializácia matíc\n",
    "\n",
    "Algoritmus inicializuje populáciu stratégií pre Blackjack, kde každá stratégia pozostáva z dvoch matíc:\n",
    "\n",
    "- **Matica hard_totals (17x10):**\n",
    "    - Riadky predstavujú súčet hráčových kariet (4-20)\n",
    "    - Stĺpce predstavujú kartu dealera (2-10, A)\n",
    "    - Hodnoty 0/1 označujú akciu (0=stand, 1=hit)\n",
    "\n",
    "- **Matica soft_totals (9x10):**\n",
    "    - Riadky predstavujú súčet hráčových kariet s použiteľným esom (12-20)\n",
    "    - Stĺpce predstavujú kartu dealera (2-10, A)\n",
    "    - Hodnoty 0/1 označujú akciu (0=stand, 1=hit)\n",
    "\n",
    "Inicializácia prebieha v metóde `create_blackjack_matrices()`, kde sa pre každú pozíciu v maticiach náhodne vyberie hodnota 0 alebo 1 (stand alebo hit).\n",
    "\n",
    "### Evolučný proces\n",
    "\n",
    "Genetický algoritmus iteratívne vylepšuje stratégie v priebehu generácií:\n",
    "\n",
    "1. **Vyhodnotenie fitness:**\n",
    "     - Každá stratégia je vyhodnotená simuláciou 20 000 hier Blackjacku.\n",
    "     - Fitness je priemerná výhra/prehra naprieč týmito hrami.\n",
    "     - Vyhodnotenie prebieha paralelne pomocou `ProcessPoolExecutor`.\n",
    "\n",
    "2. **Selekcia:**\n",
    "     - Vyberie sa najlepšia polovica stratégií podľa ich fitness hodnoty.\n",
    "     - Tieto stratégie sa stanú rodičmi pre novú generáciu.\n",
    "\n",
    "3. **Elitizmus:**\n",
    "     - Najlepšie 2 stratégie z aktuálnej generácie sú zachované bez zmeny.\n",
    "     - To zabezpečuje, že kvalita populácie neklesne.\n",
    "\n",
    "4. **Kríženie:**\n",
    "     - Nová stratégia vzniká kombináciou dvoch rodičovských stratégií.\n",
    "     - Pre každú pozíciu v matici je 50% šanca, že hodnota bude zdedená od prvého rodiča, inak od druhého.\n",
    "     - Kríženie sa vykonáva samostatne pre `hard_totals` aj `soft_totals`.\n",
    "\n",
    "5. **Mutácia:**\n",
    "     - S malou pravdepodobnosťou (`mutation_rate`, defaultne 0.01) sa hodnoty v maticiach náhodne zmenia.\n",
    "     - Mutácia prebehne inverziou hodnoty (0→1 alebo 1→0).\n",
    "     - Umožňuje algoritmu skúmať nové možnosti mimo aktuálnej populácie.\n",
    "\n",
    "Algoritmus sleduje najlepšiu stratégiu nájdenú počas celého evolučného procesu a jej fitness hodnotu. Po dokončení všetkých generácií vráti túto najlepšiu stratégiu spolu s históriou fitness pre analýzu konvergencie algoritmu.\n",
    "\n",
    "### Cieľ experimentu\n",
    "Zistiť, za akých podmienok sa genetický algoritmus dokáže najviac priblížiť k optimálnej stratégii.\n",
    "\n",
    "### Merané metriky\n",
    "- Priemerná výhra oboch stratégií pri simulácii hier\n",
    "- Percentuálna zhoda výstupnej stratégie s optimálnou stratégiou\n",
    "- Konvergenčná rýchlosť pri rôznych nastaveniach parametrov\n",
    "\n",
    "### Parametre na experimentovanie\n",
    "Budeme skúmať, ako nasledujúce parametre ovplyvňujú kvalitu výslednej stratégie:\n",
    "\n",
    "#### Veľkosť populácie (`population_size`):\n",
    "- **Menšie hodnoty (10, 20):** Rýchlejší výpočet, ale menej diverzity v populácii\n",
    "- **Väčšie hodnoty (50, 100):** Pomalší výpočet, ale potenciálne lepšie preskúmanie priestoru riešení\n",
    "\n",
    "#### Miera mutácie (`mutation_rate`):\n",
    "- **Nízke hodnoty (0.001, 0.005):** Pomalšia evolúcia, ale stabilnejšia konvergencia\n",
    "- **Stredné hodnoty (0.01, 0.02):** Vyvážená explorácia a exploitácia\n",
    "- **Vysoké hodnoty (0.05, 0.1):** Agresívnejšia explorácia, ale riziko nestability\n",
    "\n",
    "#### Počet generácií (`generations`):\n",
    "- Rôzne hodnoty (50, 100, 200, 500) na sledovanie, po koľkých generáciách dochádza k saturácii výkonnosti\n",
    "\n",
    "#### `Elite_count`:\n",
    "- Rôzne hodnoty (1, 2, 5, 10) pre posúdenie vplyvu elitizmu na kvalitu výslednej stratégie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6179aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal reward: -0.0603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882713bf8ed841d78960d17640658caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Population Sizes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Fitness = -0.2907\n",
      "Generation 2: Best Fitness = -0.2645\n",
      "Generation 3: Best Fitness = -0.2744\n",
      "Generation 4: Best Fitness = -0.258\n",
      "Generation 5: Best Fitness = -0.2454\n",
      "Generation 6: Best Fitness = -0.23\n",
      "Generation 7: Best Fitness = -0.2204\n",
      "Generation 8: Best Fitness = -0.1947\n",
      "Generation 9: Best Fitness = -0.2028\n",
      "Generation 10: Best Fitness = -0.197\n",
      "Generation 11: Best Fitness = -0.2009\n",
      "Generation 12: Best Fitness = -0.186\n",
      "Generation 13: Best Fitness = -0.1988\n",
      "Generation 14: Best Fitness = -0.1879\n",
      "Generation 15: Best Fitness = -0.1752\n",
      "Generation 16: Best Fitness = -0.1844\n",
      "Generation 17: Best Fitness = -0.1756\n",
      "Generation 18: Best Fitness = -0.1689\n",
      "Generation 19: Best Fitness = -0.1632\n",
      "Generation 20: Best Fitness = -0.1762\n",
      "Generation 21: Best Fitness = -0.1698\n",
      "Generation 22: Best Fitness = -0.172\n",
      "Generation 23: Best Fitness = -0.1598\n",
      "Generation 24: Best Fitness = -0.1577\n",
      "Generation 25: Best Fitness = -0.1562\n",
      "Generation 26: Best Fitness = -0.1518\n",
      "Generation 27: Best Fitness = -0.163\n",
      "Generation 28: Best Fitness = -0.1536\n",
      "Generation 29: Best Fitness = -0.1659\n",
      "Generation 30: Best Fitness = -0.1548\n",
      "Generation 31: Best Fitness = -0.1625\n",
      "Generation 32: Best Fitness = -0.1354\n",
      "Generation 33: Best Fitness = -0.1524\n",
      "Generation 34: Best Fitness = -0.1508\n",
      "Generation 35: Best Fitness = -0.1603\n",
      "Generation 36: Best Fitness = -0.1544\n",
      "Generation 37: Best Fitness = -0.1604\n",
      "Generation 38: Best Fitness = -0.1497\n",
      "Generation 39: Best Fitness = -0.152\n",
      "Generation 40: Best Fitness = -0.1624\n",
      "Generation 41: Best Fitness = -0.1502\n",
      "Generation 42: Best Fitness = -0.1606\n",
      "Generation 43: Best Fitness = -0.143\n",
      "Generation 44: Best Fitness = -0.1389\n",
      "Generation 45: Best Fitness = -0.1375\n",
      "Generation 46: Best Fitness = -0.1297\n",
      "Generation 47: Best Fitness = -0.1492\n",
      "Generation 48: Best Fitness = -0.1506\n",
      "Generation 49: Best Fitness = -0.1461\n",
      "Generation 50: Best Fitness = -0.148\n",
      "Generation 1: Best Fitness = -0.2876\n",
      "Generation 2: Best Fitness = -0.2552\n",
      "Generation 3: Best Fitness = -0.2314\n",
      "Generation 4: Best Fitness = -0.2286\n",
      "Generation 5: Best Fitness = -0.2228\n",
      "Generation 6: Best Fitness = -0.2074\n",
      "Generation 7: Best Fitness = -0.1876\n",
      "Generation 8: Best Fitness = -0.1918\n",
      "Generation 9: Best Fitness = -0.1943\n",
      "Generation 10: Best Fitness = -0.2015\n",
      "Generation 11: Best Fitness = -0.2056\n",
      "Generation 12: Best Fitness = -0.1965\n",
      "Generation 13: Best Fitness = -0.2011\n",
      "Generation 14: Best Fitness = -0.1726\n",
      "Generation 15: Best Fitness = -0.1814\n",
      "Generation 16: Best Fitness = -0.1661\n",
      "Generation 17: Best Fitness = -0.1678\n",
      "Generation 18: Best Fitness = -0.1673\n",
      "Generation 19: Best Fitness = -0.1668\n",
      "Generation 20: Best Fitness = -0.1612\n",
      "Generation 21: Best Fitness = -0.1656\n",
      "Generation 22: Best Fitness = -0.1617\n",
      "Generation 23: Best Fitness = -0.1515\n",
      "Generation 24: Best Fitness = -0.165\n",
      "Generation 25: Best Fitness = -0.1575\n",
      "Generation 26: Best Fitness = -0.1662\n",
      "Generation 27: Best Fitness = -0.1562\n",
      "Generation 28: Best Fitness = -0.1524\n",
      "Generation 29: Best Fitness = -0.163\n",
      "Generation 30: Best Fitness = -0.1665\n",
      "Generation 31: Best Fitness = -0.1587\n",
      "Generation 32: Best Fitness = -0.1427\n",
      "Generation 33: Best Fitness = -0.1553\n",
      "Generation 34: Best Fitness = -0.155\n",
      "Generation 35: Best Fitness = -0.152\n",
      "Generation 36: Best Fitness = -0.161\n",
      "Generation 37: Best Fitness = -0.1501\n",
      "Generation 38: Best Fitness = -0.1526\n",
      "Generation 39: Best Fitness = -0.1467\n",
      "Generation 40: Best Fitness = -0.1547\n",
      "Generation 41: Best Fitness = -0.1499\n",
      "Generation 42: Best Fitness = -0.1494\n",
      "Generation 43: Best Fitness = -0.1359\n",
      "Generation 44: Best Fitness = -0.146\n",
      "Generation 45: Best Fitness = -0.1445\n",
      "Generation 46: Best Fitness = -0.1326\n",
      "Generation 47: Best Fitness = -0.1364\n",
      "Generation 48: Best Fitness = -0.1254\n",
      "Generation 49: Best Fitness = -0.1428\n",
      "Generation 50: Best Fitness = -0.1382\n",
      "Generation 1: Best Fitness = -0.3071\n",
      "Generation 2: Best Fitness = -0.2797\n",
      "Generation 3: Best Fitness = -0.2763\n",
      "Generation 4: Best Fitness = -0.2383\n",
      "Generation 5: Best Fitness = -0.2366\n",
      "Generation 6: Best Fitness = -0.2344\n",
      "Generation 7: Best Fitness = -0.2277\n",
      "Generation 8: Best Fitness = -0.2223\n",
      "Generation 9: Best Fitness = -0.2301\n",
      "Generation 10: Best Fitness = -0.2232\n",
      "Generation 11: Best Fitness = -0.2133\n",
      "Generation 12: Best Fitness = -0.2187\n",
      "Generation 13: Best Fitness = -0.2051\n",
      "Generation 14: Best Fitness = -0.2123\n",
      "Generation 15: Best Fitness = -0.1969\n",
      "Generation 16: Best Fitness = -0.1887\n",
      "Generation 17: Best Fitness = -0.1871\n",
      "Generation 18: Best Fitness = -0.1786\n",
      "Generation 19: Best Fitness = -0.167\n",
      "Generation 20: Best Fitness = -0.1673\n",
      "Generation 21: Best Fitness = -0.1656\n",
      "Generation 22: Best Fitness = -0.1713\n",
      "Generation 23: Best Fitness = -0.1663\n",
      "Generation 24: Best Fitness = -0.1539\n",
      "Generation 25: Best Fitness = -0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-2037:\n",
      "Process ForkProcess-2038:\n",
      "Process ForkProcess-2039:\n",
      "Process ForkProcess-2036:\n",
      "Process ForkProcess-2035:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-2040:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from genetic_algorithm import BlackjackGA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from evaluate_utils import evaluate_strategy, optimal_hard_totals, optimal_soft_totals\n",
    "\n",
    "# Konfigurácie experimentu\n",
    "population_sizes = [10, 20]\n",
    "mutation_rates = [0.01, 0.05]\n",
    "generations_list = [50, 100]\n",
    "episode_counts = [10000, 20000]\n",
    "\n",
    "optimal_reward_10000 = evaluate_strategy((optimal_hard_totals, optimal_soft_totals), episodes=10000)\n",
    "optimal_reward_20000 = evaluate_strategy((optimal_hard_totals, optimal_soft_totals), episodes=20000)\n",
    "\n",
    "# Príprava dataframe pre výsledky\n",
    "results = []\n",
    "\n",
    "# Experimentovanie s rôznymi parametrami\n",
    "for pop_size in tqdm(population_sizes, desc=\"Population Sizes\"):\n",
    "    for mutation in mutation_rates:\n",
    "        for gens in generations_list:\n",
    "            for episode_count in episode_counts:\n",
    "                # Spustenie algoritmu s aktuálnymi parametrami\n",
    "                solver = BlackjackGA(population_size=pop_size, mutation_rate=mutation, generations=gens, episodes=episode_count)\n",
    "                if episode_count == 10000:\n",
    "                    optimal_reward = optimal_reward_10000\n",
    "                else:\n",
    "                    optimal_reward = optimal_reward_20000\n",
    "\n",
    "                best_strategy, best_fitness, fitness_history = solver.run()\n",
    "                \n",
    "                # Vyhodnotenie výsledkov\n",
    "                output_reward = evaluate_strategy(best_strategy, episodes=episode_count)\n",
    "                \n",
    "                # Výpočet rozdielu medzi výstupnou odmenou a optimálnou odmenou\n",
    "                reward_difference = optimal_reward - output_reward\n",
    "\n",
    "                # Uloženie výsledkov\n",
    "                results.append({\n",
    "                    'population_size': pop_size,\n",
    "                    'mutation_rate': mutation,\n",
    "                    'generations': gens,\n",
    "                    'episodes': episode_count,\n",
    "                    'output_reward': output_reward,\n",
    "                    'optimal_reward': optimal_reward,\n",
    "                    'reward_difference': reward_difference\n",
    "                })\n",
    "\n",
    "            \n",
    "\n",
    "# Konverzia na dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Zobrazenie výsledkov\n",
    "print(results_df.head())\n",
    "\n",
    "# Vizualizácia vplyvu parametrov na zhodu s optimálnou stratégiou\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='population_size', y='reward_difference', data=results_df)\n",
    "plt.title('Vplyv veľkosti populácie na zhodu s optimálnou stratégiou')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x='mutation_rate', y='reward_difference', data=results_df)\n",
    "plt.title('Vplyv miery mutácie na zhodu s optimálnou stratégiou')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='generations', y='reward_difference', data=results_df)\n",
    "plt.title('Vplyv počtu generácií na zhodu s optimálnou stratégiou')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x='episode_count', y='reward_difference', data=results_df)\n",
    "plt.title('Vplyv počtu epizod na zhodu s optimálnou stratégiou')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Vytvorenie tepelnej mapy rozdielov medzi najlepšou nájdenou stratégiou a optimálnou\n",
    "best_result_idx = results_df['reward_difference'].idxmax()\n",
    "best_params = results_df.iloc[best_result_idx]\n",
    "\n",
    "print(f\"Best parameters: population_size={best_params['population_size']}, \" +\n",
    "      f\"mutation_rate={best_params['mutation_rate']}, generations={best_params['generations']}, \" +\n",
    "      f\"elite_count={best_params['elite_count']}\")\n",
    "\n",
    "# Spustíme algoritmus s najlepšími parametrami pre vizualizáciu\n",
    "best_solver = BlackjackGA(\n",
    "    population_size=int(best_params['population_size']), \n",
    "    mutation_rate=best_params['mutation_rate'], \n",
    "    generations=int(best_params['generations']),\n",
    "    episodes=int(best_params['episode_count'])\n",
    ")\n",
    "best_strategy, fitness, fitness_history = best_solver.run()\n",
    "\n",
    "# Vizualizácia histórie fitness\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fitness_history, label='Fitness History', color='blue')\n",
    "plt.axhline(y=best_fitness, color='red', linestyle='--', label='Best Fitness')\n",
    "plt.title('Fitness History Across Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136fdaf",
   "metadata": {},
   "source": [
    "# 2. Neurónová sieť\n",
    "\n",
    "Tento kód implementuje model neurónovej siete, ktorá sa učí optimálnu stratégiu pre hru Blackjack. Model je trénovaný pomocou supervised learning na vopred definovanej optimálnej stratégii a následne je schopný predpovedať akcie (hit/stand) pre rôzne herné stavy.\n",
    "\n",
    "## Architektúra siete\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(3,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "Architektúra pozostáva z:\n",
    "\n",
    "- **Vstupnej vrstvy** pre 3 parametre:\n",
    "  - skóre hráča\n",
    "  - karta dealera\n",
    "  - použiteľné eso\n",
    "- **Dvoch skrytých vrstiev**:\n",
    "  - 64 neurónov s aktivačnou funkciou **ReLU**\n",
    "  - 32 neurónov s aktivačnou funkciou **ReLU**\n",
    "- **Výstupnej vrstvy** s aktivačnou funkciou **sigmoid**, ktorá určuje pravdepodobnosť akcie:\n",
    "  - `1 = hit`, `0 = stand`\n",
    "\n",
    "---\n",
    "\n",
    "## Trénovacie dáta\n",
    "\n",
    "Trénovacie dáta sú generované funkciou `create_training_data()`, ktorá vytvára páry **(stav, akcia)** podľa základnej stratégie Blackjacku.\n",
    "\n",
    "### Kombinácie:\n",
    "\n",
    "- **Skóre hráča**: 4–21  \n",
    "- **Karta dealera**: 1–10 (kde `1 = Eso`, `10 = 10/J/Q/K`)  \n",
    "- **Stav esa**: použiteľné / nepoužiteľné\n",
    "\n",
    "### Normalizácia vstupov (na rozsah [0,1]):\n",
    "\n",
    "- Skóre hráča: `(player_sum - 4) / 17.0`  \n",
    "- Karta dealera: `(dealer_card - 1) / 9.0`  \n",
    "- Použiteľné eso: `1` alebo `0`\n",
    "\n",
    "### Určenie akcií:\n",
    "\n",
    "- Podľa základnej stratégie pre:\n",
    "  - **Tvrdé súčty** (bez použiteľného esa)\n",
    "  - **Mäkké súčty** (s použiteľným esom)\n",
    "\n",
    "---\n",
    "\n",
    "## Parametre trénovania\n",
    "\n",
    "Trénovanie prebieha v metóde `train()` s nasledujúcimi parametrami:\n",
    "\n",
    "- `epochs` *(predvolene 100)*: počet trénovacích epoch  \n",
    "- `batch_size` *(predvolene 16)*: veľkosť dávky pre trénovanie  \n",
    "- **Validácia** na 10 % trénovacích dát  \n",
    "- **Optimalizátor**: `Adam`  \n",
    "- **Loss funkcia**: `binary_crossentropy`  \n",
    "- **Metrika**: `accuracy`\n",
    "\n",
    "---\n",
    "\n",
    "## Vyhodnocovanie modelu\n",
    "\n",
    "Model je vyhodnocovaný metódou `evaluate()`, ktorá simuluje hru Blackjack pomocou knižnice **Gymnasium**:\n",
    "\n",
    "- Prebehne `num_episodes` hier *(predvolene 20 000)*\n",
    "- V každej hre:\n",
    "  - Model určuje akciu (`hit` / `stand`) podľa aktuálneho stavu\n",
    "  - Zaznamenáva sa priemerna odmena\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbc656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 12:25:01.338930: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-11 12:25:01.340517: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-11 12:25:01.349499: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-11 12:25:01.375459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-11 12:25:01.403503: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-11 12:25:01.410212: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-11 12:25:01.433586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-11 12:25:02.413881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with layer configuration: [(32, 'relu'), (16, 'relu')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746959106.922667 2332104 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-11 12:25:06.923350: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [0.0, 0.0, 0], Action: 1\n",
      "State: [0.0, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.0, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.0, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.0, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.0, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.0, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.0, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.0, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.0, 1.0, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.0, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.058823529411764705, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.058823529411764705, 1.0, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.0, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.11764705882352941, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.11764705882352941, 1.0, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.0, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.17647058823529413, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.17647058823529413, 1.0, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.0, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.23529411764705882, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.23529411764705882, 1.0, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.0, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.29411764705882354, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.29411764705882354, 1.0, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.0, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.35294117647058826, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.35294117647058826, 1.0, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.0, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.3333333333333333, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.4444444444444444, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.5555555555555556, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.4117647058823529, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.4117647058823529, 1.0, 0], Action: 1\n",
      "State: [0.47058823529411764, 0.0, 0], Action: 1\n",
      "State: [0.47058823529411764, 0.1111111111111111, 0], Action: 1\n",
      "State: [0.47058823529411764, 0.2222222222222222, 0], Action: 1\n",
      "State: [0.47058823529411764, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.47058823529411764, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.47058823529411764, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.47058823529411764, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.47058823529411764, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.47058823529411764, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.47058823529411764, 1.0, 0], Action: 1\n",
      "State: [0.5294117647058824, 0.0, 0], Action: 0\n",
      "State: [0.5294117647058824, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.5294117647058824, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.5294117647058824, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.5294117647058824, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.5294117647058824, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.5294117647058824, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.5294117647058824, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.5294117647058824, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.5294117647058824, 1.0, 0], Action: 1\n",
      "State: [0.5882352941176471, 0.0, 0], Action: 0\n",
      "State: [0.5882352941176471, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.5882352941176471, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.5882352941176471, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.5882352941176471, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.5882352941176471, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.5882352941176471, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.5882352941176471, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.5882352941176471, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.5882352941176471, 1.0, 0], Action: 1\n",
      "State: [0.6470588235294118, 0.0, 0], Action: 0\n",
      "State: [0.6470588235294118, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.6470588235294118, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.6470588235294118, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.6470588235294118, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.6470588235294118, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.6470588235294118, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.6470588235294118, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.6470588235294118, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.6470588235294118, 1.0, 0], Action: 1\n",
      "State: [0.7058823529411765, 0.0, 0], Action: 0\n",
      "State: [0.7058823529411765, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.7058823529411765, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.7058823529411765, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.7058823529411765, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.7058823529411765, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.7058823529411765, 0.6666666666666666, 0], Action: 1\n",
      "State: [0.7058823529411765, 0.7777777777777778, 0], Action: 1\n",
      "State: [0.7058823529411765, 0.8888888888888888, 0], Action: 1\n",
      "State: [0.7058823529411765, 1.0, 0], Action: 1\n",
      "State: [0.7647058823529411, 0.0, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.6666666666666666, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.7777777777777778, 0], Action: 0\n",
      "State: [0.7647058823529411, 0.8888888888888888, 0], Action: 0\n",
      "State: [0.7647058823529411, 1.0, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.0, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.6666666666666666, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.7777777777777778, 0], Action: 0\n",
      "State: [0.8235294117647058, 0.8888888888888888, 0], Action: 0\n",
      "State: [0.8235294117647058, 1.0, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.0, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.6666666666666666, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.7777777777777778, 0], Action: 0\n",
      "State: [0.8823529411764706, 0.8888888888888888, 0], Action: 0\n",
      "State: [0.8823529411764706, 1.0, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.0, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.1111111111111111, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.2222222222222222, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.3333333333333333, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.4444444444444444, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.5555555555555556, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.6666666666666666, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.7777777777777778, 0], Action: 0\n",
      "State: [0.9411764705882353, 0.8888888888888888, 0], Action: 0\n",
      "State: [0.9411764705882353, 1.0, 0], Action: 0\n",
      "State: [1.0, 0.0, 0], Action: 0\n",
      "State: [1.0, 0.1111111111111111, 0], Action: 0\n",
      "State: [1.0, 0.2222222222222222, 0], Action: 0\n",
      "State: [1.0, 0.3333333333333333, 0], Action: 0\n",
      "State: [1.0, 0.4444444444444444, 0], Action: 0\n",
      "State: [1.0, 0.5555555555555556, 0], Action: 0\n",
      "State: [1.0, 0.6666666666666666, 0], Action: 0\n",
      "State: [1.0, 0.7777777777777778, 0], Action: 0\n",
      "State: [1.0, 0.8888888888888888, 0], Action: 0\n",
      "State: [1.0, 1.0, 0], Action: 0\n",
      "State: [0.47058823529411764, 0.0, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.1111111111111111, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.2222222222222222, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.3333333333333333, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.4444444444444444, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.5555555555555556, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.6666666666666666, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.7777777777777778, 1], Action: 1\n",
      "State: [0.47058823529411764, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.47058823529411764, 1.0, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.0, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.1111111111111111, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.2222222222222222, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.3333333333333333, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.4444444444444444, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.5555555555555556, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.6666666666666666, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.7777777777777778, 1], Action: 1\n",
      "State: [0.5294117647058824, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.5294117647058824, 1.0, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.0, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.1111111111111111, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.2222222222222222, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.3333333333333333, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.4444444444444444, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.5555555555555556, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.6666666666666666, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.7777777777777778, 1], Action: 1\n",
      "State: [0.5882352941176471, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.5882352941176471, 1.0, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.0, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.1111111111111111, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.2222222222222222, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.3333333333333333, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.4444444444444444, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.5555555555555556, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.6666666666666666, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.7777777777777778, 1], Action: 1\n",
      "State: [0.6470588235294118, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.6470588235294118, 1.0, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.0, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.1111111111111111, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.2222222222222222, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.3333333333333333, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.4444444444444444, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.5555555555555556, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.6666666666666666, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.7777777777777778, 1], Action: 1\n",
      "State: [0.7058823529411765, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.7058823529411765, 1.0, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.0, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.1111111111111111, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.2222222222222222, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.3333333333333333, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.4444444444444444, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.5555555555555556, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.6666666666666666, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.7777777777777778, 1], Action: 1\n",
      "State: [0.7647058823529411, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.7647058823529411, 1.0, 1], Action: 1\n",
      "State: [0.8235294117647058, 0.0, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.1111111111111111, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.2222222222222222, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.3333333333333333, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.4444444444444444, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.5555555555555556, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.6666666666666666, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.7777777777777778, 1], Action: 0\n",
      "State: [0.8235294117647058, 0.8888888888888888, 1], Action: 1\n",
      "State: [0.8235294117647058, 1.0, 1], Action: 1\n",
      "State: [0.8823529411764706, 0.0, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.1111111111111111, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.2222222222222222, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.3333333333333333, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.4444444444444444, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.5555555555555556, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.6666666666666666, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.7777777777777778, 1], Action: 0\n",
      "State: [0.8823529411764706, 0.8888888888888888, 1], Action: 0\n",
      "State: [0.8823529411764706, 1.0, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.0, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.1111111111111111, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.2222222222222222, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.3333333333333333, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.4444444444444444, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.5555555555555556, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.6666666666666666, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.7777777777777778, 1], Action: 0\n",
      "State: [0.9411764705882353, 0.8888888888888888, 1], Action: 0\n",
      "State: [0.9411764705882353, 1.0, 1], Action: 0\n",
      "State: [1.0, 0.0, 1], Action: 0\n",
      "State: [1.0, 0.1111111111111111, 1], Action: 0\n",
      "State: [1.0, 0.2222222222222222, 1], Action: 0\n",
      "State: [1.0, 0.3333333333333333, 1], Action: 0\n",
      "State: [1.0, 0.4444444444444444, 1], Action: 0\n",
      "State: [1.0, 0.5555555555555556, 1], Action: 0\n",
      "State: [1.0, 0.6666666666666666, 1], Action: 0\n",
      "State: [1.0, 0.7777777777777778, 1], Action: 0\n",
      "State: [1.0, 0.8888888888888888, 1], Action: 0\n",
      "State: [1.0, 1.0, 1], Action: 0\n",
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6514 - loss: 0.6535 - val_accuracy: 0.0000e+00 - val_loss: 1.0408\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6514 - loss: 0.6399 - val_accuracy: 0.0000e+00 - val_loss: 1.0948\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6514 - loss: 0.6271 - val_accuracy: 0.0000e+00 - val_loss: 1.1480\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6514 - loss: 0.6161 - val_accuracy: 0.0000e+00 - val_loss: 1.2013\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6514 - loss: 0.6060 - val_accuracy: 0.0000e+00 - val_loss: 1.2522\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6654 - loss: 0.5963 - val_accuracy: 0.0000e+00 - val_loss: 1.2942\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7032 - loss: 0.5866 - val_accuracy: 0.0000e+00 - val_loss: 1.3276\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7412 - loss: 0.5770 - val_accuracy: 0.0000e+00 - val_loss: 1.3564\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.5672 - val_accuracy: 0.0000e+00 - val_loss: 1.3855\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7519 - loss: 0.5573 - val_accuracy: 0.0000e+00 - val_loss: 1.4184\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7655 - loss: 0.5470 - val_accuracy: 0.0000e+00 - val_loss: 1.4503\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 0.5362 - val_accuracy: 0.0000e+00 - val_loss: 1.4799\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7906 - loss: 0.5244 - val_accuracy: 0.0000e+00 - val_loss: 1.5063\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8092 - loss: 0.5104 - val_accuracy: 0.0000e+00 - val_loss: 1.5303\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8189 - loss: 0.4958 - val_accuracy: 0.0000e+00 - val_loss: 1.5502\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8339 - loss: 0.4836 - val_accuracy: 0.0000e+00 - val_loss: 1.5649\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8636 - loss: 0.4693 - val_accuracy: 0.0000e+00 - val_loss: 1.5846\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8663 - loss: 0.4551 - val_accuracy: 0.0000e+00 - val_loss: 1.6048\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8734 - loss: 0.4410 - val_accuracy: 0.0000e+00 - val_loss: 1.6155\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8842 - loss: 0.4270 - val_accuracy: 0.0000e+00 - val_loss: 1.6110\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8942 - loss: 0.4119 - val_accuracy: 0.0000e+00 - val_loss: 1.5989\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9053 - loss: 0.4003 - val_accuracy: 0.0000e+00 - val_loss: 1.5886\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.3875 - val_accuracy: 0.0000e+00 - val_loss: 1.5778\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.3753 - val_accuracy: 0.0000e+00 - val_loss: 1.5632\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9105 - loss: 0.3631 - val_accuracy: 0.0000e+00 - val_loss: 1.5447\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.3507 - val_accuracy: 0.0000e+00 - val_loss: 1.5228\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9098 - loss: 0.3398 - val_accuracy: 0.0000e+00 - val_loss: 1.4991\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9006 - loss: 0.3298 - val_accuracy: 0.0000e+00 - val_loss: 1.4739\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9061 - loss: 0.3190 - val_accuracy: 0.0000e+00 - val_loss: 1.4285\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9061 - loss: 0.3087 - val_accuracy: 0.0357 - val_loss: 1.4042\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9125 - loss: 0.2987 - val_accuracy: 0.0357 - val_loss: 1.3847\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9144 - loss: 0.2892 - val_accuracy: 0.0714 - val_loss: 1.3557\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9171 - loss: 0.2802 - val_accuracy: 0.1071 - val_loss: 1.3207\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9171 - loss: 0.2719 - val_accuracy: 0.1071 - val_loss: 1.2870\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9171 - loss: 0.2640 - val_accuracy: 0.1429 - val_loss: 1.2587\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9171 - loss: 0.2564 - val_accuracy: 0.1786 - val_loss: 1.2291\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9151 - loss: 0.2494 - val_accuracy: 0.1786 - val_loss: 1.1987\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9165 - loss: 0.2429 - val_accuracy: 0.2143 - val_loss: 1.1684\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2368 - val_accuracy: 0.2500 - val_loss: 1.1370\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9165 - loss: 0.2312 - val_accuracy: 0.2500 - val_loss: 1.1053\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9165 - loss: 0.2259 - val_accuracy: 0.2857 - val_loss: 1.0745\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9317 - loss: 0.2211 - val_accuracy: 0.2857 - val_loss: 1.0454\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9317 - loss: 0.2162 - val_accuracy: 0.3214 - val_loss: 1.0155\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9326 - loss: 0.2119 - val_accuracy: 0.3571 - val_loss: 0.9887\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9334 - loss: 0.2079 - val_accuracy: 0.3571 - val_loss: 0.9648\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.2042 - val_accuracy: 0.3571 - val_loss: 0.9415\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.2007 - val_accuracy: 0.3929 - val_loss: 0.9186\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9326 - loss: 0.1983 - val_accuracy: 0.4286 - val_loss: 0.8953\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.1945 - val_accuracy: 0.4643 - val_loss: 0.8747\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9299 - loss: 0.1917 - val_accuracy: 0.4643 - val_loss: 0.8558\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.1891 - val_accuracy: 0.4643 - val_loss: 0.8370\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9299 - loss: 0.1866 - val_accuracy: 0.4643 - val_loss: 0.8182\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.1844 - val_accuracy: 0.5000 - val_loss: 0.7995\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9346 - loss: 0.1823 - val_accuracy: 0.5714 - val_loss: 0.7817\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9346 - loss: 0.1803 - val_accuracy: 0.5714 - val_loss: 0.7659\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9355 - loss: 0.1785 - val_accuracy: 0.5714 - val_loss: 0.7506\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9355 - loss: 0.1767 - val_accuracy: 0.5714 - val_loss: 0.7350\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.1751 - val_accuracy: 0.5714 - val_loss: 0.7203\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9353 - loss: 0.1744 - val_accuracy: 0.5714 - val_loss: 0.7078\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.1720 - val_accuracy: 0.5714 - val_loss: 0.6968\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.1706 - val_accuracy: 0.5714 - val_loss: 0.6834\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9355 - loss: 0.1693 - val_accuracy: 0.6429 - val_loss: 0.6689\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.1698 - val_accuracy: 0.6429 - val_loss: 0.6572\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9355 - loss: 0.1670 - val_accuracy: 0.6786 - val_loss: 0.6479\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9355 - loss: 0.1658 - val_accuracy: 0.6786 - val_loss: 0.6393\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.1647 - val_accuracy: 0.6786 - val_loss: 0.6273\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9454 - loss: 0.1638 - val_accuracy: 0.6786 - val_loss: 0.6157\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9454 - loss: 0.1628 - val_accuracy: 0.6786 - val_loss: 0.6071\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1619 - val_accuracy: 0.6786 - val_loss: 0.5976\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1610 - val_accuracy: 0.6786 - val_loss: 0.5875\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1602 - val_accuracy: 0.6786 - val_loss: 0.5778\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9480 - loss: 0.1594 - val_accuracy: 0.6786 - val_loss: 0.5711\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1586 - val_accuracy: 0.6786 - val_loss: 0.5616\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9416 - loss: 0.1579 - val_accuracy: 0.7143 - val_loss: 0.5508\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1585 - val_accuracy: 0.7500 - val_loss: 0.5435\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1555 - val_accuracy: 0.7500 - val_loss: 0.5372\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9416 - loss: 0.1558 - val_accuracy: 0.7857 - val_loss: 0.5300\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9416 - loss: 0.1551 - val_accuracy: 0.7857 - val_loss: 0.5212\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9416 - loss: 0.1546 - val_accuracy: 0.7857 - val_loss: 0.5138\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1540 - val_accuracy: 0.7857 - val_loss: 0.5069\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.1556 - val_accuracy: 0.7857 - val_loss: 0.5016\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9416 - loss: 0.1528 - val_accuracy: 0.7857 - val_loss: 0.4960\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9409 - loss: 0.1526 - val_accuracy: 0.7857 - val_loss: 0.4893\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1518 - val_accuracy: 0.7857 - val_loss: 0.4809\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1513 - val_accuracy: 0.7857 - val_loss: 0.4760\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1507 - val_accuracy: 0.7857 - val_loss: 0.4755\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1502 - val_accuracy: 0.7857 - val_loss: 0.4683\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1498 - val_accuracy: 0.7857 - val_loss: 0.4605\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.1494 - val_accuracy: 0.7857 - val_loss: 0.4544\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1490 - val_accuracy: 0.7857 - val_loss: 0.4493\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9471 - loss: 0.1488 - val_accuracy: 0.8214 - val_loss: 0.4440\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9478 - loss: 0.1497 - val_accuracy: 0.8214 - val_loss: 0.4396\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1477 - val_accuracy: 0.8214 - val_loss: 0.4347\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.1473 - val_accuracy: 0.8571 - val_loss: 0.4284\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1470 - val_accuracy: 0.8571 - val_loss: 0.4236\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1466 - val_accuracy: 0.8571 - val_loss: 0.4206\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1462 - val_accuracy: 0.8571 - val_loss: 0.4150\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9515 - loss: 0.1459 - val_accuracy: 0.8571 - val_loss: 0.4095\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9515 - loss: 0.1455 - val_accuracy: 0.8571 - val_loss: 0.4079\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.1450 - val_accuracy: 0.8571 - val_loss: 0.4014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m learner \u001b[38;5;241m=\u001b[39m BlackjackNN(layer_config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m     24\u001b[0m history \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m model_reward \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     29\u001b[0m config_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m units, _ \u001b[38;5;129;01min\u001b[39;00m config])\n",
      "File \u001b[0;32m~/fit_projekty/BIN/blackjack-solver/neural_network.py:218\u001b[0m, in \u001b[0;36mBlackjackNN.evaluate\u001b[0;34m(self, num_episodes)\u001b[0m\n\u001b[1;32m    215\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m--> 218\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    220\u001b[0m     done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/fit_projekty/BIN/blackjack-solver/neural_network.py:206\u001b[0m, in \u001b[0;36mBlackjackNN.get_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    199\u001b[0m normalized_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m    200\u001b[0m     [(player_sum \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m17.0\u001b[39m],\n\u001b[1;32m    201\u001b[0m     [(dealer_card \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m9.0\u001b[39m],\n\u001b[1;32m    202\u001b[0m     [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m usable_ace \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    203\u001b[0m ])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Predict action (sigmoid output > 0.5 -> hit, otherwise stand)\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:507\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    505\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    508\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m    509\u001b[0m         data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:687\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m    690\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[1;32m    691\u001b[0m         ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 709\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 748\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neural_network import BlackjackNN, optimal_hard_totals, optimal_soft_totals, evaluate_strategy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "    \n",
    "layer_configs = [\n",
    "    [(32, 'relu'), (16, 'relu')],\n",
    "    [(64, 'relu'), (32, 'relu')],\n",
    "    [(128, 'relu'), (64, 'relu')]\n",
    "]\n",
    "\n",
    "optimal_reward = evaluate_strategy((optimal_hard_totals, optimal_soft_totals))\n",
    "\n",
    "for config in layer_configs:\n",
    "    print(f\"\\nTraining with layer configuration: {config}\")\n",
    "    learner = BlackjackNN(layer_config=config)\n",
    "    history = learner.train(epochs=100, batch_size=32)\n",
    "    \n",
    "    model_reward = learner.evaluate()\n",
    "    \n",
    "    # Save results\n",
    "    config_name = '-'.join([f\"{units}\" for units, _ in config])\n",
    "    results.append({\n",
    "        'config': config_name,\n",
    "        'optimal_reward': optimal_reward,\n",
    "        'model_reward': model_reward,\n",
    "        'reward_difference': abs(optimal_reward) - abs(model_reward),\n",
    "        'accuracy': max(history.history['val_accuracy']),\n",
    "        'num_layers': len(config),\n",
    "        'total_neurons': sum([units for units, _ in config])\n",
    "    })\n",
    "    \n",
    "    print(f\"Optimal Strategy Avg Reward: {optimal_reward:.4f}\")\n",
    "    print(f\"Model Strategy Avg Reward: {model_reward:.4f}\")\n",
    "    print(f\"Difference: {optimal_reward - model_reward:.4f}\")\n",
    "    print(f\"Validation Accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Create visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot reward comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='config', y='model_reward', data=results_df, color='blue', label='Model')\n",
    "sns.barplot(x='config', y='optimal_reward', data=results_df, color='green', alpha=0.5, label='Optimal')\n",
    "plt.title('Model vs Optimal Strategy Reward')\n",
    "plt.xlabel('Network Configuration (neurons per layer)')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.legend()\n",
    "\n",
    "# Plot reward difference\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(x='config', y='reward_difference', data=results_df)\n",
    "plt.title('Reward Difference (Optimal - Model)')\n",
    "plt.xlabel('Network Configuration (neurons per layer)')\n",
    "plt.ylabel('Difference')\n",
    "\n",
    "# Plot accuracy vs. network size\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x='total_neurons', y='accuracy', size='num_layers', data=results_df, sizes=(100, 200))\n",
    "plt.title('Accuracy vs Network Size')\n",
    "plt.xlabel('Total Neurons')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "\n",
    "# Plot accuracy vs. reward difference\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x='accuracy', y='reward_difference', hue='config', data=results_df, s=100)\n",
    "plt.title('Accuracy vs Reward Difference')\n",
    "plt.xlabel('Validation Accuracy')\n",
    "plt.ylabel('Reward Difference (Optimal - Model)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('network_configurations_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary of Network Configurations:\")\n",
    "summary = results_df[['config', 'model_reward', 'optimal_reward', 'reward_difference', 'accuracy']]\n",
    "summary = summary.sort_values('reward_difference')\n",
    "print(summary.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "\n",
    "# # Plot training history\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Loss During Training')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "    \n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Accuracy During Training')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.savefig('training_history.png')\n",
    "# plt.show()\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
